block_type: "transformer"
learn_prosody: True

duration_modeling:
  learn_alignment: False
  aligner_temperature: 0.0005

prosody:
  # Du et al., 2021
  learn_mixture: True # This is only supported under supervised duration modeling (learn_alignment: False)
  extractor_kernel_size: 9
  predictor_kernel_size: [9, 5]
  predictor_num_gaussians: 20
  predictor_dropout: 0.2

transformer:
  encoder_layer: 4
  encoder_head: 2
  encoder_hidden: 256
  decoder_layer: 6
  decoder_head: 2
  decoder_hidden: 256
  conv_filter_size: 1024
  conv_kernel_size: [9, 1]
  encoder_dropout: 0.2
  decoder_dropout: 0.2

conformer:
  encoder_layer: 4
  encoder_head: 8
  encoder_hidden: 256
  decoder_layer: 6
  decoder_head: 8
  decoder_hidden: 256
  feed_forward_expansion_factor: 4
  conv_expansion_factor: 2
  conv_kernel_size: 31
  half_step_residual: True
  encoder_dropout: 0.1
  decoder_dropout: 0.1

reformer:
  depth: 6
  encoder_head: 8
  decoder_head: 8

variance_predictor:
  filter_size: 256
  kernel_size: 3
  dropout: 0.5

variance_embedding:
  kernel_size: 9
  pitch_quantization: "linear" # support 'linear' or 'log', 'log' is allowed only if the pitch values are not normalized during preprocessing
  energy_quantization: "linear" # support 'linear' or 'log', 'log' is allowed only if the energy values are not normalized during preprocessing
  n_bins: 256

multi_speaker: False

max_seq_len: 1000

vocoder:
  model: "HiFi-GAN" # support 'HiFi-GAN', 'MelGAN'
  speaker: "LJSpeech" # support  'LJSpeech', 'universal'
